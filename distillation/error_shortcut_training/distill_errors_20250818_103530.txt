/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-08-18 10:35:53,552 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 2
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-08-18 10:35:53,685 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/feature_pixart',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=True,
    load_t5_feat=True,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/feature_pixart'
)
image_size = 512
train_batch_size = 8
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = False
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = False
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 3
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/shortcut_training/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_finetuning/checkpoints/epoch_1_step_37990.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/shortcut_training/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [
    8, 9, 11, 12, 13, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27
]
final_output_loss_flag = True
transformer_blocks = [8, 15, 17, 20, 11, 16]
trainable_blocks = []
reserve_memory = False
stable_loss = True
image_list_json = ['data_info.json']
data_stable_loss = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/feature_pixart',
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images',
    image_list_json=['data_info_stable_loss.json'],
    transform='default_train',
    load_vae_feat=True,
    load_t5_feat=True,
    load_img_vae_feat=False)
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
log_interval_stable_loss = 1000
org_loss_flag = False

2025-08-18 10:35:53,685 - PixArt - INFO - World_size: 2, seed: 43
2025-08-18 10:35:53,685 - PixArt - INFO - Initializing: DDP for training
2025-08-18 10:35:53,685 - PixArt - INFO - vae scale factor: 0.13025
2025-08-18 10:35:53,686 - PixArt - INFO - Preparing Visualization prompt embeddings...
2025-08-18 10:35:53,686 - PixArt - INFO - Loading text encoder and tokenizer from /export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers ...
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.94s/it]
2025-08-18 10:36:15,513 - PixArt - WARNING - position embed interpolation: 1.0, base size: 32
2025-08-18 10:36:15,513 - PixArt - WARNING - kv compress config: {'sampling': None, 'scale_factor': 1, 'kv_compress_layer': []}
2025-08-18 10:36:30,386 - PixArt - WARNING - position embed interpolation: 1.0, base size: 32
2025-08-18 10:36:30,386 - PixArt - WARNING - kv compress config: {'sampling': None, 'scale_factor': 1, 'kv_compress_layer': []}
2025-08-18 10:36:37,582 - PixArt - INFO - PixArtMS Model Parameters: 610,856,096
2025-08-18 10:36:40,010 - PixArt - INFO - Load checkpoint from /export/data/sheid/pixart/shortcut_training/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_finetuning/checkpoints/epoch_1_step_37990.pth. Load ema: False.
2025-08-18 10:36:41,293 - PixArt - INFO - Load checkpoint from /export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth. Load ema: False.
2025-08-18 10:36:41,296 - PixArt - WARNING - Missing keys: ['pos_embed', 'blocks.8.scale_shift_table', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.cross_attn.q_linear.weight', 'blocks.8.cross_attn.q_linear.bias', 'blocks.8.cross_attn.kv_linear.weight', 'blocks.8.cross_attn.kv_linear.bias', 'blocks.8.cross_attn.proj.weight', 'blocks.8.cross_attn.proj.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.11.scale_shift_table', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.cross_attn.q_linear.weight', 'blocks.11.cross_attn.q_linear.bias', 'blocks.11.cross_attn.kv_linear.weight', 'blocks.11.cross_attn.kv_linear.bias', 'blocks.11.cross_attn.proj.weight', 'blocks.11.cross_attn.proj.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'blocks.15.scale_shift_table', 'blocks.15.attn.qkv.weight', 'blocks.15.attn.qkv.bias', 'blocks.15.attn.proj.weight', 'blocks.15.attn.proj.bias', 'blocks.15.cross_attn.q_linear.weight', 'blocks.15.cross_attn.q_linear.bias', 'blocks.15.cross_attn.kv_linear.weight', 'blocks.15.cross_attn.kv_linear.bias', 'blocks.15.cross_attn.proj.weight', 'blocks.15.cross_attn.proj.bias', 'blocks.15.mlp.fc1.weight', 'blocks.15.mlp.fc1.bias', 'blocks.15.mlp.fc2.weight', 'blocks.15.mlp.fc2.bias', 'blocks.16.scale_shift_table', 'blocks.16.attn.qkv.weight', 'blocks.16.attn.qkv.bias', 'blocks.16.attn.proj.weight', 'blocks.16.attn.proj.bias', 'blocks.16.cross_attn.q_linear.weight', 'blocks.16.cross_attn.q_linear.bias', 'blocks.16.cross_attn.kv_linear.weight', 'blocks.16.cross_attn.kv_linear.bias', 'blocks.16.cross_attn.proj.weight', 'blocks.16.cross_attn.proj.bias', 'blocks.16.mlp.fc1.weight', 'blocks.16.mlp.fc1.bias', 'blocks.16.mlp.fc2.weight', 'blocks.16.mlp.fc2.bias', 'blocks.17.scale_shift_table', 'blocks.17.attn.qkv.weight', 'blocks.17.attn.qkv.bias', 'blocks.17.attn.proj.weight', 'blocks.17.attn.proj.bias', 'blocks.17.cross_attn.q_linear.weight', 'blocks.17.cross_attn.q_linear.bias', 'blocks.17.cross_attn.kv_linear.weight', 'blocks.17.cross_attn.kv_linear.bias', 'blocks.17.cross_attn.proj.weight', 'blocks.17.cross_attn.proj.bias', 'blocks.17.mlp.fc1.weight', 'blocks.17.mlp.fc1.bias', 'blocks.17.mlp.fc2.weight', 'blocks.17.mlp.fc2.bias', 'blocks.20.scale_shift_table', 'blocks.20.attn.qkv.weight', 'blocks.20.attn.qkv.bias', 'blocks.20.attn.proj.weight', 'blocks.20.attn.proj.bias', 'blocks.20.cross_attn.q_linear.weight', 'blocks.20.cross_attn.q_linear.bias', 'blocks.20.cross_attn.kv_linear.weight', 'blocks.20.cross_attn.kv_linear.bias', 'blocks.20.cross_attn.proj.weight', 'blocks.20.cross_attn.proj.bias', 'blocks.20.mlp.fc1.weight', 'blocks.20.mlp.fc1.bias', 'blocks.20.mlp.fc2.weight', 'blocks.20.mlp.fc2.bias']
2025-08-18 10:36:41,296 - PixArt - WARNING - Unexpected keys: []
2025-08-18 10:36:41,298 - PixArt - INFO - PixArtMS Model Parameters: 483,322,784
2025-08-18 10:36:41,299 - PixArt - INFO - PixArtMS Trainable Model Parameters: 483,322,784
2025-08-18 10:36:41,300 - PixArt - INFO - Constructing dataset InternalDataMSSigma...
2025-08-18 10:36:41,301 - PixArt - INFO - T5 max token length: 300
2025-08-18 10:36:41,301 - PixArt - INFO - ratio of real user prompt: 1.0
2025-08-18 10:36:41,607 - PixArt - INFO - data_info.json data volume: 100000
2025-08-18 10:36:42,931 - PixArt - INFO - Dataset InternalDataMSSigma constructed. time: 1.63 s, length (use/ori): 100000/100000
2025-08-18 10:36:42,932 - PixArt - INFO - Constructing dataset InternalDataMSSigma...
2025-08-18 10:36:42,932 - PixArt - INFO - T5 max token length: 300
2025-08-18 10:36:42,932 - PixArt - INFO - ratio of real user prompt: 1.0
2025-08-18 10:36:42,935 - PixArt - INFO - data_info_stable_loss.json data volume: 499
2025-08-18 10:36:42,943 - PixArt - INFO - Dataset InternalDataMSSigma constructed. time: 0.01 s, length (use/ori): 499/499
2025-08-18 10:36:42,944 - PixArt - INFO - Automatically adapt lr to 0.00001 (using sqrt scaling rule).
2025-08-18 10:36:42,989 - PixArt - INFO - CAMEWrapper Optimizer: total 345 param groups, 345 are learnable, 0 are fix. Lr group: 345 params with lr 0.00001; Weight decay group: 345 params with weight decay 0.03.
2025-08-18 10:36:42,989 - PixArt - INFO - Lr schedule: constant, num_warmup_steps:1000.
  0%|          | 0/6250 [00:00<?, ?it/s]  0%|          | 0/6250 [00:00<?, ?it/s]

  0%|          | 0/32 [00:00<?, ?it/s][A  0%|          | 0/32 [00:00<?, ?it/s][A
  3%|▎         | 1/32 [00:01<00:44,  1.44s/it][A
  3%|▎         | 1/32 [00:01<00:46,  1.49s/it][A
  6%|▋         | 2/32 [00:01<00:26,  1.12it/s][A
  6%|▋         | 2/32 [00:02<00:27,  1.09it/s][A
  9%|▉         | 3/32 [00:02<00:20,  1.38it/s][A
  9%|▉         | 3/32 [00:02<00:21,  1.36it/s][A
 12%|█▎        | 4/32 [00:02<00:17,  1.56it/s][A
 12%|█▎        | 4/32 [00:03<00:18,  1.53it/s][A
 16%|█▌        | 5/32 [00:03<00:16,  1.68it/s][A
 16%|█▌        | 5/32 [00:03<00:16,  1.66it/s][A
 19%|█▉        | 6/32 [00:04<00:14,  1.76it/s][A
 19%|█▉        | 6/32 [00:04<00:14,  1.75it/s][A
 22%|██▏       | 7/32 [00:04<00:13,  1.82it/s][A
 22%|██▏       | 7/32 [00:04<00:13,  1.81it/s][A
 25%|██▌       | 8/32 [00:05<00:12,  1.85it/s][A
 25%|██▌       | 8/32 [00:05<00:12,  1.85it/s][A
 28%|██▊       | 9/32 [00:05<00:12,  1.88it/s][A
 28%|██▊       | 9/32 [00:05<00:12,  1.88it/s][A
 31%|███▏      | 10/32 [00:06<00:11,  1.89it/s][A
 31%|███▏      | 10/32 [00:06<00:11,  1.90it/s][A
 34%|███▍      | 11/32 [00:06<00:11,  1.91it/s][A
 34%|███▍      | 11/32 [00:06<00:11,  1.91it/s][A
 38%|███▊      | 12/32 [00:07<00:10,  1.92it/s][A
 38%|███▊      | 12/32 [00:07<00:10,  1.92it/s][A
 41%|████      | 13/32 [00:07<00:09,  1.92it/s][A
 41%|████      | 13/32 [00:07<00:09,  1.93it/s][A
 44%|████▍     | 14/32 [00:08<00:09,  1.93it/s][A
 44%|████▍     | 14/32 [00:08<00:09,  1.93it/s][A
 47%|████▋     | 15/32 [00:08<00:08,  1.93it/s][A
 47%|████▋     | 15/32 [00:08<00:08,  1.94it/s][A
 50%|█████     | 16/32 [00:09<00:08,  1.93it/s][A
 50%|█████     | 16/32 [00:09<00:08,  1.94it/s][A
 53%|█████▎    | 17/32 [00:09<00:07,  1.93it/s][A
 53%|█████▎    | 17/32 [00:09<00:07,  1.94it/s][A
 56%|█████▋    | 18/32 [00:10<00:07,  1.93it/s][A
 56%|█████▋    | 18/32 [00:10<00:07,  1.94it/s][A
 59%|█████▉    | 19/32 [00:10<00:06,  1.93it/s][A
 59%|█████▉    | 19/32 [00:10<00:06,  1.94it/s][A
 62%|██████▎   | 20/32 [00:11<00:06,  1.93it/s][A
 62%|██████▎   | 20/32 [00:11<00:06,  1.94it/s][A
 66%|██████▌   | 21/32 [00:11<00:05,  1.92it/s][A
 66%|██████▌   | 21/32 [00:11<00:05,  1.94it/s][A
 69%|██████▉   | 22/32 [00:12<00:05,  1.93it/s][A
 69%|██████▉   | 22/32 [00:12<00:05,  1.93it/s][A
 72%|███████▏  | 23/32 [00:12<00:04,  1.93it/s][A
 72%|███████▏  | 23/32 [00:12<00:04,  1.93it/s][A
 75%|███████▌  | 24/32 [00:13<00:04,  1.93it/s][A
 75%|███████▌  | 24/32 [00:13<00:04,  1.94it/s][A
 78%|███████▊  | 25/32 [00:13<00:03,  1.93it/s][A
 78%|███████▊  | 25/32 [00:13<00:03,  1.94it/s][A
 81%|████████▏ | 26/32 [00:14<00:03,  1.93it/s][A
 81%|████████▏ | 26/32 [00:14<00:03,  1.94it/s][A
 84%|████████▍ | 27/32 [00:14<00:02,  1.94it/s][A
 84%|████████▍ | 27/32 [00:14<00:02,  1.91it/s][A
 88%|████████▊ | 28/32 [00:15<00:02,  1.93it/s][A
 88%|████████▊ | 28/32 [00:15<00:02,  1.92it/s][A
 91%|█████████ | 29/32 [00:15<00:01,  1.93it/s][A
 91%|█████████ | 29/32 [00:15<00:01,  1.92it/s][A
 94%|█████████▍| 30/32 [00:16<00:01,  1.94it/s][A
 94%|█████████▍| 30/32 [00:16<00:01,  1.93it/s][A
 97%|█████████▋| 31/32 [00:16<00:00,  1.94it/s][A
 97%|█████████▋| 31/32 [00:16<00:00,  1.93it/s][A
100%|██████████| 32/32 [00:17<00:00,  1.67it/s][A100%|██████████| 32/32 [00:17<00:00,  1.80it/s]

100%|██████████| 32/32 [00:17<00:00,  1.58it/s][A100%|██████████| 32/32 [00:17<00:00,  1.79it/s]
2025-08-18 10:37:06,002 - PixArt - INFO - Step/Epoch [1/1][1/6250]:total_eta: 3 days, 1:19:48, epoch_eta:18:19:51, time_all:1.056, time_data:0.049, lr:0.000e+00, s:(32, 32), loss:1.6119, grad_norm:inf, stable_loss:1.4461
  0%|          | 1/6250 [00:21<36:46:38, 21.19s/it]2025-08-18 10:37:06,360 - PixArt - INFO - Running validation... 

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 11.63it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.71it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 11.71it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 11.73it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 11.75it/s][A
 92%|█████████▏| 12/13 [00:01<00:00, 11.74it/s][A100%|██████████| 13/13 [00:01<00:00, 12.66it/s]

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 11.78it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.55it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 11.60it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 11.49it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 11.58it/s][A
 92%|█████████▏| 12/13 [00:01<00:00, 11.61it/s][A100%|██████████| 13/13 [00:01<00:00, 12.52it/s]

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 11.84it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.84it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 11.83it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 11.82it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 11.81it/s][A
 92%|█████████▏| 12/13 [00:01<00:00, 11.80it/s][A100%|██████████| 13/13 [00:01<00:00, 12.75it/s]

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 11.78it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.73it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 11.76it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 11.71it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 11.71it/s][A
 92%|█████████▏| 12/13 [00:01<00:00, 11.73it/s][A100%|██████████| 13/13 [00:01<00:00, 12.66it/s]

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 11.88it/s][A
 31%|███       | 4/13 [00:00<00:00, 11.77it/s][A
 46%|████▌     | 6/13 [00:00<00:00, 11.78it/s][A
 62%|██████▏   | 8/13 [00:00<00:00, 11.72it/s][A
 77%|███████▋  | 10/13 [00:00<00:00, 11.76it/s][A
 92%|█████████▏| 12/13 [00:01<00:00, 11.79it/s][A100%|██████████| 13/13 [00:01<00:00, 12.71it/s]
  0%|          | 1/6250 [00:29<51:54:54, 29.91s/it]  0%|          | 2/6250 [00:31<25:35:06, 14.74s/it]  0%|          | 2/6250 [00:31<22:51:48, 13.17s/it]  0%|          | 3/6250 [00:32<15:02:53,  8.67s/it]  0%|          | 3/6250 [00:32<13:34:15,  7.82s/it]  0%|          | 4/6250 [00:34<10:16:47,  5.92s/it]  0%|          | 4/6250 [00:34<9:23:07,  5.41s/it]   0%|          | 5/6250 [00:36<7:35:56,  4.38s/it]   0%|          | 5/6250 [00:36<7:01:36,  4.05s/it]  0%|          | 6/6250 [00:37<5:58:52,  3.45s/it]  0%|          | 6/6250 [00:37<5:36:15,  3.23s/it]  0%|          | 7/6250 [00:39<4:57:03,  2.85s/it]  0%|          | 7/6250 [00:39<4:41:52,  2.71s/it]  0%|          | 8/6250 [00:41<4:16:44,  2.47s/it]  0%|          | 8/6250 [00:41<4:06:21,  2.37s/it]  0%|          | 9/6250 [00:42<3:49:49,  2.21s/it]  0%|          | 9/6250 [00:42<3:42:40,  2.14s/it]  0%|          | 10/6250 [00:44<3:31:31,  2.03s/it]  0%|          | 10/6250 [00:44<3:26:32,  1.99s/it]  0%|          | 11/6250 [00:46<3:18:31,  1.91s/it]  0%|          | 11/6250 [00:45<3:15:09,  1.88s/it]  0%|          | 12/6250 [00:47<3:10:01,  1.83s/it]  0%|          | 12/6250 [00:47<3:07:37,  1.80s/it]  0%|          | 13/6250 [00:49<3:03:56,  1.77s/it]  0%|          | 13/6250 [00:49<3:02:16,  1.75s/it]  0%|          | 14/6250 [00:50<3:00:19,  1.74s/it]  0%|          | 14/6250 [00:50<2:59:08,  1.72s/it]  0%|          | 15/6250 [00:52<2:57:29,  1.71s/it]  0%|          | 15/6250 [00:52<2:56:40,  1.70s/it]  0%|          | 16/6250 [00:54<2:55:14,  1.69s/it]  0%|          | 16/6250 [00:54<2:54:39,  1.68s/it]  0%|          | 17/6250 [00:55<2:53:38,  1.67s/it]  0%|          | 17/6250 [00:55<2:53:15,  1.67s/it]  0%|          | 18/6250 [00:57<2:52:45,  1.66s/it]  0%|          | 18/6250 [00:57<2:52:28,  1.66s/it]  0%|          | 19/6250 [00:59<2:52:19,  1.66s/it]  0%|          | 19/6250 [00:59<2:52:07,  1.66s/it]  0%|          | 20/6250 [01:00<2:51:48,  1.65s/it]2025-08-18 10:37:45,656 - PixArt - INFO - Step/Epoch [20/1][20/6250]:total_eta: 20:04:50, epoch_eta:5:00:29, time_all:1.983, time_data:0.442, lr:1.700e-07, s:(32, 32), loss:1.2960, grad_norm:inf
  0%|          | 20/6250 [01:00<2:51:41,  1.65s/it]  0%|          | 21/6250 [01:02<2:51:29,  1.65s/it]  0%|          | 21/6250 [01:02<2:51:24,  1.65s/it]  0%|          | 22/6250 [01:04<2:51:06,  1.65s/it]  0%|          | 22/6250 [01:04<2:51:07,  1.65s/it]  0%|          | 23/6250 [01:05<2:50:45,  1.65s/it]  0%|          | 23/6250 [01:05<2:50:40,  1.64s/it]  0%|          | 24/6250 [01:07<2:50:31,  1.64s/it]  0%|          | 24/6250 [01:07<2:50:31,  1.64s/it]  0%|          | 25/6250 [01:09<2:50:06,  1.64s/it]  0%|          | 25/6250 [01:08<2:50:03,  1.64s/it]  0%|          | 26/6250 [01:10<2:49:59,  1.64s/it]  0%|          | 26/6250 [01:10<2:49:58,  1.64s/it]  0%|          | 27/6250 [01:12<2:50:12,  1.64s/it]  0%|          | 27/6250 [01:12<2:50:12,  1.64s/it]  0%|          | 28/6250 [01:13<2:50:09,  1.64s/it]  0%|          | 28/6250 [01:13<2:50:09,  1.64s/it]  0%|          | 29/6250 [01:15<2:50:07,  1.64s/it]  0%|          | 29/6250 [01:15<2:50:07,  1.64s/it]  0%|          | 30/6250 [01:17<2:50:08,  1.64s/it]  0%|          | 30/6250 [01:17<2:50:06,  1.64s/it]  0%|          | 31/6250 [01:18<2:50:01,  1.64s/it]  0%|          | 31/6250 [01:18<2:50:00,  1.64s/it]  1%|          | 32/6250 [01:20<2:49:45,  1.64s/it]  1%|          | 32/6250 [01:20<2:49:45,  1.64s/it]  1%|          | 33/6250 [01:22<2:58:09,  1.72s/it]  1%|          | 33/6250 [01:22<2:58:10,  1.72s/it]  1%|          | 34/6250 [01:24<2:55:33,  1.69s/it]  1%|          | 34/6250 [01:23<2:55:33,  1.69s/it]  1%|          | 35/6250 [01:25<2:53:51,  1.68s/it]  1%|          | 35/6250 [01:25<2:53:53,  1.68s/it]  1%|          | 36/6250 [01:27<2:52:35,  1.67s/it]  1%|          | 36/6250 [01:27<2:52:35,  1.67s/it]  1%|          | 37/6250 [01:28<2:52:04,  1.66s/it]  1%|          | 37/6250 [01:28<2:52:02,  1.66s/it]  1%|          | 38/6250 [01:30<2:51:46,  1.66s/it]  1%|          | 38/6250 [01:30<2:51:46,  1.66s/it]  1%|          | 39/6250 [01:32<2:51:12,  1.65s/it]  1%|          | 39/6250 [01:32<2:51:13,  1.65s/it]  1%|          | 40/6250 [01:33<2:50:49,  1.65s/it]2025-08-18 10:38:18,741 - PixArt - INFO - Step/Epoch [40/1][40/6250]:total_eta: 15:52:17, epoch_eta:3:56:56, time_all:1.654, time_data:0.003, lr:3.700e-07, s:(32, 32), loss:1.3897, grad_norm:37.1627
  1%|          | 40/6250 [01:33<2:50:49,  1.65s/it]  1%|          | 41/6250 [01:35<2:50:43,  1.65s/it]  1%|          | 41/6250 [01:35<2:50:41,  1.65s/it]