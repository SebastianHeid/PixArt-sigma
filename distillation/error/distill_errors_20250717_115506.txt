/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 11:55:31,723 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 11:55:31,810 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 11:55:31,810 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 11:55:31,810 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:39<00:00, 19.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:39<00:00, 19.65s/it]
2025-07-17 11:56:25,455 - PixArt - INFO - vae scale factor: 0.13025
2025-07-17 11:56:25,457 - PixArt - INFO - Preparing Visualization prompt embeddings...
2025-07-17 11:56:33,475 - PixArt - WARNING - position embed interpolation: 1.0, base size: 32
2025-07-17 11:56:33,475 - PixArt - WARNING - kv compress config: {'sampling': None, 'scale_factor': 1, 'kv_compress_layer': []}
2025-07-17 11:56:46,255 - PixArt - WARNING - position embed interpolation: 1.0, base size: 32
2025-07-17 11:56:46,255 - PixArt - WARNING - kv compress config: {'sampling': None, 'scale_factor': 1, 'kv_compress_layer': []}
2025-07-17 11:56:52,478 - PixArt - INFO - PixArtMS Model Parameters: 610,856,096
2025-07-17 11:56:59,089 - PixArt - INFO - Load checkpoint from /export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth. Load ema: False.
2025-07-17 11:57:04,477 - PixArt - INFO - Load checkpoint from /export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth. Load ema: False.
2025-07-17 11:57:04,480 - PixArt - WARNING - Missing keys: ['pos_embed', 'blocks.8.scale_shift_table', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.cross_attn.q_linear.weight', 'blocks.8.cross_attn.q_linear.bias', 'blocks.8.cross_attn.kv_linear.weight', 'blocks.8.cross_attn.kv_linear.bias', 'blocks.8.cross_attn.proj.weight', 'blocks.8.cross_attn.proj.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.11.scale_shift_table', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.cross_attn.q_linear.weight', 'blocks.11.cross_attn.q_linear.bias', 'blocks.11.cross_attn.kv_linear.weight', 'blocks.11.cross_attn.kv_linear.bias', 'blocks.11.cross_attn.proj.weight', 'blocks.11.cross_attn.proj.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'blocks.12.scale_shift_table', 'blocks.12.attn.qkv.weight', 'blocks.12.attn.qkv.bias', 'blocks.12.attn.proj.weight', 'blocks.12.attn.proj.bias', 'blocks.12.cross_attn.q_linear.weight', 'blocks.12.cross_attn.q_linear.bias', 'blocks.12.cross_attn.kv_linear.weight', 'blocks.12.cross_attn.kv_linear.bias', 'blocks.12.cross_attn.proj.weight', 'blocks.12.cross_attn.proj.bias', 'blocks.12.mlp.fc1.weight', 'blocks.12.mlp.fc1.bias', 'blocks.12.mlp.fc2.weight', 'blocks.12.mlp.fc2.bias', 'blocks.15.scale_shift_table', 'blocks.15.attn.qkv.weight', 'blocks.15.attn.qkv.bias', 'blocks.15.attn.proj.weight', 'blocks.15.attn.proj.bias', 'blocks.15.cross_attn.q_linear.weight', 'blocks.15.cross_attn.q_linear.bias', 'blocks.15.cross_attn.kv_linear.weight', 'blocks.15.cross_attn.kv_linear.bias', 'blocks.15.cross_attn.proj.weight', 'blocks.15.cross_attn.proj.bias', 'blocks.15.mlp.fc1.weight', 'blocks.15.mlp.fc1.bias', 'blocks.15.mlp.fc2.weight', 'blocks.15.mlp.fc2.bias', 'blocks.16.scale_shift_table', 'blocks.16.attn.qkv.weight', 'blocks.16.attn.qkv.bias', 'blocks.16.attn.proj.weight', 'blocks.16.attn.proj.bias', 'blocks.16.cross_attn.q_linear.weight', 'blocks.16.cross_attn.q_linear.bias', 'blocks.16.cross_attn.kv_linear.weight', 'blocks.16.cross_attn.kv_linear.bias', 'blocks.16.cross_attn.proj.weight', 'blocks.16.cross_attn.proj.bias', 'blocks.16.mlp.fc1.weight', 'blocks.16.mlp.fc1.bias', 'blocks.16.mlp.fc2.weight', 'blocks.16.mlp.fc2.bias', 'blocks.17.scale_shift_table', 'blocks.17.attn.qkv.weight', 'blocks.17.attn.qkv.bias', 'blocks.17.attn.proj.weight', 'blocks.17.attn.proj.bias', 'blocks.17.cross_attn.q_linear.weight', 'blocks.17.cross_attn.q_linear.bias', 'blocks.17.cross_attn.kv_linear.weight', 'blocks.17.cross_attn.kv_linear.bias', 'blocks.17.cross_attn.proj.weight', 'blocks.17.cross_attn.proj.bias', 'blocks.17.mlp.fc1.weight', 'blocks.17.mlp.fc1.bias', 'blocks.17.mlp.fc2.weight', 'blocks.17.mlp.fc2.bias', 'blocks.20.scale_shift_table', 'blocks.20.attn.qkv.weight', 'blocks.20.attn.qkv.bias', 'blocks.20.attn.proj.weight', 'blocks.20.attn.proj.bias', 'blocks.20.cross_attn.q_linear.weight', 'blocks.20.cross_attn.q_linear.bias', 'blocks.20.cross_attn.kv_linear.weight', 'blocks.20.cross_attn.kv_linear.bias', 'blocks.20.cross_attn.proj.weight', 'blocks.20.cross_attn.proj.bias', 'blocks.20.mlp.fc1.weight', 'blocks.20.mlp.fc1.bias', 'blocks.20.mlp.fc2.weight', 'blocks.20.mlp.fc2.bias', 'blocks.23.scale_shift_table', 'blocks.23.attn.qkv.weight', 'blocks.23.attn.qkv.bias', 'blocks.23.attn.proj.weight', 'blocks.23.attn.proj.bias', 'blocks.23.cross_attn.q_linear.weight', 'blocks.23.cross_attn.q_linear.bias', 'blocks.23.cross_attn.kv_linear.weight', 'blocks.23.cross_attn.kv_linear.bias', 'blocks.23.cross_attn.proj.weight', 'blocks.23.cross_attn.proj.bias', 'blocks.23.mlp.fc1.weight', 'blocks.23.mlp.fc1.bias', 'blocks.23.mlp.fc2.weight', 'blocks.23.mlp.fc2.bias']
2025-07-17 11:57:04,480 - PixArt - WARNING - Unexpected keys: []
2025-07-17 11:57:04,484 - PixArt - INFO - PixArtMS Model Parameters: 419,556,128
2025-07-17 11:57:04,485 - PixArt - INFO - PixArtMS Trainable Model Parameters: 21,255,552
2025-07-17 11:57:04,485 - PixArt - INFO - Constructing dataset InternalDataMSSigma...
2025-07-17 11:57:04,486 - PixArt - INFO - T5 max token length: 300
2025-07-17 11:57:04,486 - PixArt - INFO - ratio of real user prompt: 1.0
2025-07-17 11:57:05,712 - PixArt - INFO - data_info.json data volume: 609431
2025-07-17 11:57:13,710 - PixArt - INFO - Dataset InternalDataMSSigma constructed. time: 9.22 s, length (use/ori): 609428/609431
2025-07-17 11:57:13,711 - PixArt - WARNING - Using valid_num=0 in config file. Available 40 aspect_ratios: ['0.25', '0.26', '0.27', '0.28', '0.32', '0.33', '0.35', '0.4', '0.42', '0.48', '0.5', '0.52', '0.57', '0.6', '0.68', '0.72', '0.78', '0.82', '0.88', '0.94', '1.0', '1.07', '1.13', '1.21', '1.29', '1.38', '1.46', '1.67', '1.75', '2.0', '2.09', '2.4', '2.5', '2.89', '3.0', '3.11', '3.62', '3.75', '3.88', '4.0']
2025-07-17 11:57:13,712 - PixArt - INFO - Automatically adapt lr to 0.00001 (using sqrt scaling rule).
2025-07-17 11:57:13,749 - PixArt - INFO - CAMEWrapper Optimizer: total 300 param groups, 15 are learnable, 285 are fix. Lr group: 15 params with lr 0.00001; Weight decay group: 15 params with weight decay 0.03.
2025-07-17 11:57:13,749 - PixArt - INFO - Lr schedule: constant, num_warmup_steps:1000.
  0%|          | 0/38089 [00:00<?, ?it/s]  0%|          | 0/38089 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 722, in <module>
    train()
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 178, in train
    for step, batch in enumerate(tqdm(train_dataloader)):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/accelerate/data_loader.py", line 566, in __iter__
    current_batch = next(dataloader_iter)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/export/home/sheid/PixArt-sigma/diffusion/data/datasets/InternalData_ms.py", line 369, in __getitem__
    raise RuntimeError('Too many bad data.')
RuntimeError: Too many bad data.
[2025-07-17 11:57:19,569] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4107426) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_11:57:19
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4107426)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 11:57:41,613 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 11:57:41,699 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 11:57:41,699 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 11:57:41,699 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 9.81 MiB is free. Including non-PyTorch memory, this process has 9.41 GiB memory in use. Process 4108596 has 29.95 GiB memory in use. Of the allocated memory 9.00 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 11:57:51,858] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4108431) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_11:57:51
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4108431)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 11:58:12,890 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 11:58:12,983 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 11:58:12,983 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 11:58:12,983 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 71.81 MiB is free. Process 4108596 has 29.96 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 11:58:24,285] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4109123) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_11:58:24
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4109123)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 11:59:28,857 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 11:59:28,943 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 11:59:28,943 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 11:59:28,943 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 65.81 MiB is free. Process 4108596 has 29.97 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 11:59:36,913] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4111220) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_11:59:36
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4111220)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 11:59:57,506 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 11:59:57,593 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 11:59:57,593 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 11:59:57,593 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 65.81 MiB is free. Process 4108596 has 29.97 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:00:08,811] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4111829) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:00:08
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4111829)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:00:27,130 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:00:27,221 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:00:27,221 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:00:27,221 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 65.81 MiB is free. Process 4108596 has 29.97 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:00:35,834] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4112427) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:00:35
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4112427)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:01:35,843 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:01:35,931 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:01:35,931 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:01:35,931 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 23.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:01:47,551] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4113093) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:01:47
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4113093)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:02:07,253 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:02:07,342 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:02:07,342 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:02:07,342 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 23.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:02:19,413] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4113372) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:02:19
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4113372)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:02:40,033 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:02:40,125 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:02:40,125 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:02:40,125 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:02:51,516] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4113639) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:02:51
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4113639)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:03:48,570 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:03:48,655 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:03:48,655 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:03:48,655 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:04:00,421] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4114193) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:04:00
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4114193)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:04:20,268 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:04:20,352 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:04:20,352 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:04:20,353 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:04:32,501] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4114434) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:04:32
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4114434)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:04:52,966 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:04:53,054 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:04:53,054 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:04:53,054 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:05:04,877] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4114688) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:05:04
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4114688)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:06:02,043 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:06:02,129 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:06:02,130 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:06:02,130 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:06:12,690] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4115824) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:06:12
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4115824)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:06:30,247 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:06:30,335 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:06:30,335 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:06:30,335 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:06:39,779] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4116066) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:06:39
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4116066)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:06:58,872 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:06:58,976 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:06:58,976 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:06:58,976 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 19.81 MiB is free. Process 4108596 has 30.59 GiB memory in use. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.34 GiB is allocated by PyTorch, and 4.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:07:06,850] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4116284) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:07:06
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4116284)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:08:01,972 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:08:02,060 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/dzavadsk/datasets/laion/subset_250/images/'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = [13]
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:08:02,060 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:08:02,060 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 5.81 MiB is free. Process 4117286 has 29.95 GiB memory in use. Including non-PyTorch memory, this process has 9.41 GiB memory in use. Of the allocated memory 9.00 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:08:14,797] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4117487) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:08:14
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4117487)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:08:32,491 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:08:32,582 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root='/export/data/vislearn/rother_subgroup/sheid/pixart/laion',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/rother_datasets/LaionAE/laion2B-en-art_512'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 1
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 38000
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:08:32,582 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:08:32,582 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 69.81 MiB is free. Process 4117286 has 29.97 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:08:41,751] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4118358) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:08:41
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4118358)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-07-17 12:09:01,911 - PixArt - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-07-17 12:09:02,008 - PixArt - INFO - Config: 
data_root = 'pixart-sigma-toy-dataset'
data = dict(
    type='InternalDataMSSigma',
    root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/json',
    image_list_json=['data_info.json'],
    transform='default_train',
    load_vae_feat=False,
    load_t5_feat=False,
    img_root=
    '/export/data/vislearn/rother_subgroup/sheid/pixart/pixart_generated_images/images'
)
image_size = 512
train_batch_size = 16
eval_batch_size = 16
use_fsdp = False
valid_num = 0
fp32_attention = True
model = 'PixArtMS_XL_2'
aspect_ratio_type = 'ASPECT_RATIO_512'
multi_scale = True
pe_interpolation = 1.0
qk_norm = False
kv_compress = False
kv_compress_config = dict(sampling=None, scale_factor=1, kv_compress_layer=[])
num_workers = 0
train_sampling_steps = 1000
visualize = True
deterministic_validation = False
eval_sampling_steps = 500
model_max_length = 300
lora_rank = 4
num_epochs = 2
gradient_accumulation_steps = 1
grad_checkpointing = True
gradient_clip = 0.01
gc_step = 1
auto_lr = dict(rule='sqrt')
validation_prompts = [
    'dog',
    'portrait photo of a girl, photograph, highly detailed face, depth of field',
    'Self-portrait oil painting, a beautiful cyborg with golden hair, 8k',
    'Astronaut in a jungle, cold color palette, muted colors, detailed, 8k',
    'A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece'
]
optimizer = dict(
    type='CAMEWrapper',
    lr=2e-05,
    weight_decay=0.03,
    eps=(1e-30, 1e-16),
    betas=(0.9, 0.999, 0.9999))
lr_schedule = 'constant'
lr_schedule_args = dict(num_warmup_steps=1000)
save_image_epochs = 1
save_model_epochs = 1
save_model_steps = 12500
sample_posterior = True
mixed_precision = 'fp16'
scale_factor = 0.13025
ema_rate = 0.9999
tensorboard_mox_interval = 50
log_interval = 20
cfg_scale = 4
mask_type = 'null'
num_group_tokens = 0
mask_loss_coef = 0.0
load_mask_index = False
vae_pretrained = '/export/scratch/sheid/pixart/pixart_sigma_sdxlvae_T5_diffusers/vae'
load_from = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning/checkpoints/epoch_1_step_38000.pth'
resume_from = None
snr_loss = False
real_prompt_ratio = 1.0
class_dropout_prob = 0.1
work_dir = '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images'
s3_work_dir = None
micro_condition = False
seed = 43
skip_step = 0
loss_type = 'huber'
huber_c = 0.001
num_ddim_timesteps = 50
w_max = 15.0
w_min = 3.0
ema_decay = 0.95
intermediate_loss_flag = True
intermediate_loss_blocks = [8, 9, 12, 17, 18, 20, 21, 23, 24, 25]
final_output_loss_flag = True
transformer_blocks = [17, 15, 8, 20, 11, 16, 12, 23, 14]
trainable_blocks = []
image_list_json = ['data_info.json']
ref_load_from = '/export/scratch/sheid/pixart/PixArt-Sigma-XL-2-512-MS.pth'
org_loss_flag = False

2025-07-17 12:09:02,009 - PixArt - INFO - World_size: 1, seed: 43
2025-07-17 12:09:02,009 - PixArt - INFO - Initializing: DDP for training
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/train_scripts/train.py", line 480, in <module>
    text_encoder = T5EncoderModel.from_pretrained(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3698, in to
    return super().to(*args, **kwargs)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 67.81 MiB is free. Process 4117286 has 29.97 GiB memory in use. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 8.92 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-07-17 12:09:13,880] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 4119094) of binary: /export/scratch/sheid/miniconda3/envs/pixart/bin/python
Traceback (most recent call last):
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/export/home/sheid/PixArt-sigma/train_scripts/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-17_12:09:13
  host      : compgpu7
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4119094)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 258, in <module>
    main(config)
  File "/export/home/sheid/PixArt-sigma/tools/convert_pixart_to_diffusers_distillation.py", line 32, in main
    all_state_dict = torch.load(args.orig_ckpt_path, map_location=torch.device('cpu'))
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 998, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 445, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/torch/serialization.py", line 426, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500.pth'
/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Traceback (most recent call last):
  File "/export/home/sheid/MasterThesis_Evaluation/block_analysis_distillation.py", line 151, in <module>
    state_dict = load_file(config.checkpoint_path + block_str + "_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_"+str(config.epochs_pixart_training)+"_step_"+str(config.training_steps)+"/transformer/diffusion_pytorch_model.safetensors")
  File "/export/scratch/sheid/miniconda3/envs/pixart/lib/python3.9/site-packages/safetensors/torch.py", line 313, in load_file
    with safe_open(filename, framework="pt", device=device) as f:
FileNotFoundError: No such file or directory: "/export/data/sheid/pixart/second_pruning_attempt/PixArt_sigma_xl2_img512_laion_17_15_8_20_11_16_12_23_14_finetuning_trained_on_pixart_generated_images/checkpoints/epoch_2_step_12500/transformer/diffusion_pytorch_model.safetensors"
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/create_eval_yaml.py", line 66, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
Traceback (most recent call last):
  File "/export/home/sheid/PixArt-sigma/distillation/update_config_distillation.py", line 32, in <module>
    with open(config.log_path + "/_temp_new_removed_blocks.json", "r") as new_blocks_file:
FileNotFoundError: [Errno 2] No such file or directory: '/export/home/sheid/MasterThesis_Evaluation/block_analyis_pixart/distiallation/5//_temp_new_removed_blocks.json'
